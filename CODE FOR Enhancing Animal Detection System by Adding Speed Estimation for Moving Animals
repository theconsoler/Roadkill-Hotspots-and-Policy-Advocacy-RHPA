import cv2
import numpy as np
from ultralytics import YOLO

# Load YOLOv5 model
model = YOLO("C:/Users/ASUS/Downloads/JUPYTER PROJECTS/RHPA PROJECT/yolov5xu.pt")

# Load input video
video_path = "C:/Users/ASUS/Downloads/JUPYTER PROJECTS/RHPA PROJECT/Deer crash.mp4"
cap = cv2.VideoCapture(video_path)

# Get video properties
frame_width = int(cap.get(3))
frame_height = int(cap.get(4))
fps = int(cap.get(cv2.CAP_PROP_FPS))
scale_factor = 0.05  # Approximate meters per pixel (adjust based on real data)

# Define codec and create VideoWriter object
output_path = "C:/Users/ASUS/Downloads/JUPYTER PROJECTS/RHPA PROJECT/output_speed_video.mp4"
fourcc = cv2.VideoWriter_fourcc(*'mp4v')  
out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

# Read the first frame
ret, prev_frame = cap.read()
prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

# Process video frame-by-frame
while cap.isOpened():
    ret, next_frame = cap.read()
    if not ret:
        break

    next_gray = cv2.cvtColor(next_frame, cv2.COLOR_BGR2GRAY)

    # Compute Optical Flow
    flow = cv2.calcOpticalFlowFarneback(prev_gray, next_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)

    # Calculate displacement (sum of all motion vectors)
    movement = np.mean(np.abs(flow))

    # Convert to speed (meters per second)
    speed_mps = movement * fps * scale_factor
    speed_kph = speed_mps * 3.6  # Convert to km/h

    # Detect animals with YOLO
    results = model(next_frame)

    for result in results:
        boxes = result.boxes.xyxy.cpu().numpy()  # Get bounding boxes

        for box in boxes:
            x_min, y_min, x_max, y_max = map(int, box)

            # Draw bounding box
            cv2.rectangle(next_frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)

            # Display speed on frame
            label = f"Speed: {speed_kph:.2f} km/h"
            cv2.putText(next_frame, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

    # Write processed frame to output video
    out.write(next_frame)

    # Update previous frame for next iteration
    prev_gray = next_gray

cap.release()
out.release()

print(f"Processed video saved at: {output_path}")
